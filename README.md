# Literature:
Use this space to write new references (link to the paper, name, etc.):



## [Content](#content)

<table>
<tr><td colspan="2"><a href="#cognitive-science">1. Cognitive Science</a></td></tr> 
<tr><td colspan="2"><a href="#state-representation-learning">2. State Representation Learning</a></td></tr>
<tr><td colspan="2"><a href="#hierarchical-reinforcement-learning">3. Hierarchical Reinforcement Learning</a></td></tr>
<tr><td colspan="2"><a href="#gnnrl">4. GNN+RL</a></td></tr>
<tr><td colspan="2"><a href="#various">5. Various</a></td></tr>

</table>

## [Cognitive Science](#content)
1. **Reward is enough, 2021** [Link](https://www.sciencedirect.com/science/article/pii/S0004370221000862)

    *David Silver, Satinder Singh, Doina Precup, Richard S.Sutton* 

2. **Hierarchical principles of embodied reinforcement learning: A review, 2022** [Link](https://arxiv.org/abs/2012.10147)

    *Manfred Eppe, Christian Gumbsch, Matthias Kerzel, Phuong D.H. Nguyen, Martin V. Butz, Stefan Wermter* 

    
    
## [State Representation Learning](#content)

1. **Planning to Explore via Self-Supervised World Models, 2022** [Link](https://arxiv.org/abs/2005.05960)

    *Ramanan Sekar, Oleh Rybkin, Kostas Daniilidis, Pieter Abbeel, Danijar Hafner, Deepak Pathak* 
    
2. **Reinforcement Learning with Prototypical Representations, 2021** [Link](https://arxiv.org/abs/2102.11271)

    *Denis Yarats, Rob Fergus, Alessandro Lazaric, Lerrel Pinto* 
    
    Notes: I have been able to replicate the results.


## [Hierarchical Reinforcement Learning](#content)

## [GNN+RL](#content)
1. **NerveNet: Learning Structured Policy with Graph Neural Networks , 2018**[Link](https://openreview.net/forum?id=S1sqHMZCb)

*Tingwu Wang, Renjie Liao, Jimmy Ba, Sanja Fidler*

2. **Planning to Explore via Self-Supervised World Models, 2022** [Link](https://arxiv.org/abs/2005.05960)

    *Ramanan Sekar, Oleh Rybkin, Kostas Daniilidis, Pieter Abbeel, Danijar Hafner, Deepak Pathak* 

## [Various](#content)
